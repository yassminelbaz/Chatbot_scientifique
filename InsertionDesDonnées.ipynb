{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT DATA IN TABLE ARTICLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Lire les variables depuis .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "articles_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/articles_cleaned_final.csv\")\n",
    "#authors_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/authors_table1.csv\")\n",
    "\n",
    "# Connexion à MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME \n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insertion des articles\n",
    "for _, row in articles_df.iterrows():\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT INTO articles (id_article, title, abstract, year, doi, domain)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\", (\n",
    "        row['id_article'],\n",
    "        row['title'],\n",
    "        row['abstract'],\n",
    "        int(row['year']),\n",
    "        str(row['doi']),\n",
    "        row['domain']\n",
    "    ))\n",
    "\n",
    "\n",
    "# Finaliser\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT DATA IN TABLE AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Lire les variables depuis .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "# Charger les fichiers CSV\n",
    "#articles_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/articles_cleaned1.csv\")\n",
    "authors_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/authors_table_cleaned_final.csv\")\n",
    "\n",
    "# Connexion à MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME \n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "\n",
    "# Insertion des auteurs\n",
    "for _, row in authors_df.iterrows():\n",
    "    if pd.notna(row['author']):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO authors (author_id, author)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", (\n",
    "            row['author_id'],\n",
    "            row['author']\n",
    "        ))\n",
    "\n",
    "# Finaliser\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT DATA IN TABLE KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Lire les variables depuis .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "# Charger les keywords\n",
    "keywords_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/keywords_table_cleaned_final.csv\")\n",
    "\n",
    "# Fonction de nettoyage du mot-clé\n",
    "def clean_keyword(kw):\n",
    "    if isinstance(kw, str):\n",
    "        for word in [\"primary\", \"secondary\"]:\n",
    "            kw = kw.replace(word, \"\").strip()\n",
    "    return kw\n",
    "\n",
    "# Nettoyer la colonne 'keyword'\n",
    "keywords_df['keyword'] = keywords_df['keyword'].apply(clean_keyword)\n",
    "\n",
    "# Connexion à MySQL\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME \n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insertion des keywords\n",
    "for _, row in keywords_df.iterrows():\n",
    "    if pd.notna(row['keyword']):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT INTO keywords (keyword_id, keyword)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", (\n",
    "            row['keyword_id'],\n",
    "            row['keyword']\n",
    "        ))\n",
    "\n",
    "# Finaliser\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT DATA IN TABLE ARTICLE_AUTHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Lire les variables depuis .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "article_author_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/article_author_cleaned_final.csv\")\n",
    "\n",
    "# Connexion\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME \n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insertion\n",
    "for _, row in article_author_df.iterrows():\n",
    "    if pd.notna(row['id_article']) and pd.notna(row['author_id']):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO article_author (id_article, author_id)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", (\n",
    "            row['id_article'],\n",
    "            row['author_id']\n",
    "        ))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSERT DATA IN TABLE ARTICLE_KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# Lire les variables depuis .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "\n",
    "# Charger les données\n",
    "article_keyword_df = pd.read_csv(\"D:/MachineLearning/Project/Output_Data/Article_keyword_cleaned_final.csv\")\n",
    "\n",
    "# Connexion\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME \n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Insertion\n",
    "for _, row in article_keyword_df.iterrows():\n",
    "    if pd.notna(row['id_article']) and pd.notna(row['keyword_id']):\n",
    "        cursor.execute(\"\"\"\n",
    "            INSERT IGNORE INTO article_keyword (id_article, keyword_id)\n",
    "            VALUES (%s, %s)\n",
    "        \"\"\", (\n",
    "            row['id_article'],\n",
    "            row['keyword_id']\n",
    "        ))\n",
    "\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
