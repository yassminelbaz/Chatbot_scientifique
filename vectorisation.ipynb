{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faa275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "# 2. Lire les variables depuis le fichier .env\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# 3. Connexion à la base de données\n",
    "conn = mysql.connector.connect(\n",
    "    host=DB_HOST,\n",
    "    user=DB_USER,\n",
    "    password=DB_PASSWORD,\n",
    "    database=DB_NAME\n",
    ")\n",
    "\n",
    "# 4. Requête SQL (tu peux retirer le LIMIT si tu veux tout)\n",
    "query = \"\"\"\n",
    "SELECT id_article, title, abstract, year, doi,domain\n",
    "FROM articles\n",
    "WHERE abstract IS NOT NULL AND abstract != ''\n",
    "\"\"\"\n",
    "\n",
    "# 5. Chargement des résultats dans un DataFrame\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# 6. Fermer la connexion\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b082658",
   "metadata": {},
   "source": [
    "chargement du module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d10c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Charger le modèle\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d104d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S'assurer que les abstracts sont en string\n",
    "abstracts = df['abstract'].astype(str).tolist()\n",
    "\n",
    "# Vectorisation avec barre de progression\n",
    "embeddings = model.encode(abstracts, show_progress_bar=True, convert_to_numpy=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf377ca",
   "metadata": {},
   "source": [
    "moteur de recherche faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7663e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Obtenir la dimension des vecteurs\n",
    "dim = embeddings.shape[1]\n",
    "\n",
    "# Créer l’index FAISS (utilise la distance euclidienne L2)\n",
    "index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "# Ajouter les vecteurs à l’index\n",
    "index.add(embeddings)\n",
    "\n",
    "# ✅ Sauvegarder l’index\n",
    "faiss.write_index(index, \"faiss_index_articles.index\")\n",
    "\n",
    "# ✅ Sauvegarder les ID des articles associés aux embeddings (important pour la recherche plus tard)\n",
    "np.save(\"indexed_article_ids.npy\", df['id_article'].values)\n",
    "\n",
    "# (Facultatif) Sauvegarder les métadonnées pour vérification humaine\n",
    "df[['id_article', 'title', 'abstract', 'year', 'doi']].to_csv(\"articles_metadata.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5224a28f",
   "metadata": {},
   "source": [
    "fonction de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccf6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "# Charger l’index FAISS\n",
    "index = faiss.read_index(\"faiss_index_articles.index\")\n",
    "\n",
    "# Charger les ID alignés avec les embeddings\n",
    "article_ids = np.load(\"indexed_article_ids.npy\",allow_pickle=True)\n",
    "\n",
    "# Charger le modèle de recherche sémantique\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Fonction de recherche\n",
    "def search_semantically(query, k=5):\n",
    "    # Étape 1 : encoder la requête\n",
    "    query_embedding = model.encode([query])\n",
    "\n",
    "    # Étape 2 : rechercher les plus proches voisins dans FAISS\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Étape 3 : récupérer les IDs d'article correspondants\n",
    "    ids_articles = [article_ids[i] for i in indices[0]]\n",
    "\n",
    "\n",
    "    if not ids_articles:\n",
    "        return []\n",
    "\n",
    "    # Étape 4 : se connecter à la base de données\n",
    "    conn = mysql.connector.connect(\n",
    "        host=DB_HOST,\n",
    "        user=DB_USER,\n",
    "        password=DB_PASSWORD,\n",
    "        database=DB_NAME\n",
    "    )\n",
    "    cursor = conn.cursor(dictionary=True)\n",
    "\n",
    "    # Construire la requête SQL dynamique\n",
    "    placeholders = ','.join(['%s'] * len(ids_articles))\n",
    "    sql = f\"\"\"\n",
    "        SELECT a.id_article, a.title, a.abstract, a.year, a.doi,\n",
    "               GROUP_CONCAT(au.author SEPARATOR ', ') AS authors\n",
    "        FROM articles a\n",
    "        LEFT JOIN article_author aa ON a.id_article = aa.id_article\n",
    "        LEFT JOIN authors au ON aa.author_id = au.author_id\n",
    "        WHERE a.id_article IN ({placeholders})\n",
    "        GROUP BY a.id_article\n",
    "    \"\"\"\n",
    "    cursor.execute(sql, ids_articles)\n",
    "    results = cursor.fetchall()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return results\n",
    "query = \"medical diagnosis\"\n",
    "results = search_semantically(query, k=5)\n",
    "\n",
    "if results:\n",
    "    print(f\"\\nNombre de résultats trouvés : {len(results)}\")\n",
    "    for i, article in enumerate(results, 1):\n",
    "        print(f\"\\n--- Résultat {i} ---\")\n",
    "        print(f\"Titre     : {article['title']}\")\n",
    "        print(f\"Auteur(s) : {article['authors']}\")\n",
    "        print(f\"Année     : {article['year']}\")\n",
    "        print(f\"DOI       : {article['doi']}\")\n",
    "        print(f\"Résumé    : {article['abstract'][:300]}...\")\n",
    "else:\n",
    "    print(\"Aucun résultat trouvé.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
